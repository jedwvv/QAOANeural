{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained neural network sizes. It is of the form [N, s_1, s_2, ..., s_N] where N = number of layers, s_i = #nodes of layer i\n",
    "network_sizes = [ (2, 36, 6), (3, 36, 36, 6), (3, 36, 6, 6), (4, 36, 36, 6, 6), (4, 36, 36, 36, 6), (5, 36, 36, 36, 6, 6) ]\n",
    "\n",
    "#Regularisation parameters used for each of the neural network sizes\n",
    "regularisations = [ 0.0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 5.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_networks = {}\n",
    "for network_size, reg in product(network_sizes, regularisations):\n",
    "    no_layers = network_size[0]\n",
    "    nodes_per_layer = list( network_size[1:] )\n",
    "    trained_network_data = \"NN[{}]_reg={}.json\".format(\",\".join([str(x) for x in nodes_per_layer]), reg)\n",
    "    with open(\"trained_networks/\"+trained_network_data, \"r\") as f:\n",
    "        trained_networks[(network_size, reg)] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E.g. To get trained network of 2 layers, with neurons 36, 6 and regularisation 0.05\n",
    "def access_trainednetwork(no_layers, nodes_per_layer, regularisation):\n",
    "    arg1 = tuple( [no_layers] + nodes_per_layer )\n",
    "    arg2 = regularisation\n",
    "    return trained_networks[ (arg1, arg2) ]\n",
    "\n",
    "no_layers = 2\n",
    "nodes_per_layer = [36, 6]\n",
    "reg = 0.05\n",
    "network1 = access_trainednetwork(no_layers=no_layers, nodes_per_layer=nodes_per_layer, regularisation=reg)\n",
    "\n",
    "\"\"\" From training script, this is the order of values:\n",
    "training_data = [\n",
    "        list(opt_result.x),\n",
    "        opt_result.fun,\n",
    "        [ list(res.x) for res in opt_hist ],\n",
    "        [res.fun for res in opt_hist],\n",
    "        ] \n",
    "\"\"\"\n",
    "#E.g.\n",
    "trained_weights = np.array( network1[0] )\n",
    "training_error = network1[1]\n",
    "intermediate_weights = network1[2]\n",
    "intermediate_errors = network1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_neural_network import flatten_weights, reshape_weights, forward_pass\n",
    "from train_neural_network import cost as cost_network\n",
    "from train_neural_network import backpropagated_gradient as gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check loaded functions and loaded values agree on trainin set\n",
    "network1_weights = reshape_weights( trained_weights, nodes_per_layer )\n",
    "x_train = np.loadtxt(\"datasets/training_x_inputs.csv\", delimiter=\",\")\n",
    "y_train = np.loadtxt(\"datasets/training_y_outputs.csv\", delimiter=\",\")\n",
    "print(\"Cost calculated: {}\".format( cost_network( network1_weights, x=x_train, y=y_train ) ) )\n",
    "print(\"Cost loaded: {}\".format(training_error) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now check error on validation set\n",
    "x_valid = np.loadtxt(\"datasets/validation_x_inputs.csv\", delimiter=\",\")\n",
    "y_valid = np.loadtxt(\"datasets/validation_y_outputs.csv\", delimiter=\",\")\n",
    "print(\"Cost calculated: {}\".format( cost_network( network1_weights, x=x_valid, y=y_valid ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate validation loss per intermediate step:\n",
    "def get_training_validation_loss(no_layers, nodes_per_layer, reg, x_valid, y_valid):\n",
    "    network = access_trainednetwork(no_layers=no_layers, nodes_per_layer=nodes_per_layer, regularisation=reg)\n",
    "    intermediate_weights = network[2]\n",
    "    training_loss = network[3]\n",
    "    validation_loss = []\n",
    "    for wt in intermediate_weights:\n",
    "        wt = np.asarray(wt, dtype=np.float128)\n",
    "        wt = reshape_weights( wt, nodes_per_layer )\n",
    "        loss = cost_network( wt, x_valid, y_valid )\n",
    "        validation_loss += [loss]\n",
    "    return training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularisations_to_plot = regularisations[::2]\n",
    "column_args = network_sizes[:3]\n",
    "fig, axs = plt.subplots( nrows=len(regularisations_to_plot), ncols=len(column_args), figsize=(16,20), dpi=150 )\n",
    "for k, reg in enumerate(regularisations_to_plot):\n",
    "    for j, arg in enumerate(column_args):\n",
    "        no_layers = arg[0]\n",
    "        nodes_per_layer = list( arg[1:] )\n",
    "        training_loss, validation_loss = get_training_validation_loss(no_layers=no_layers, \n",
    "                                                                        nodes_per_layer=nodes_per_layer,\n",
    "                                                                        reg=reg,\n",
    "                                                                        x_valid=x_valid,\n",
    "                                                                        y_valid=y_valid\n",
    "                                                                        )\n",
    "        axs[k, j].plot( validation_loss, label = \"validation\" )\n",
    "        axs[k, j].plot( training_loss, label = \"training\" )\n",
    "        if j == 0:\n",
    "            axs[k, j].set_ylabel(\"$\\lambda$={}\".format(reg))\n",
    "        if k == 0:\n",
    "            axs[k, j].set_title(\"Network size: {}\".format(arg))\n",
    "        \n",
    "axs[k,j].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularisations_to_plot = regularisations\n",
    "column_args = network_sizes[3:]\n",
    "fig, axs = plt.subplots( nrows=len(regularisations_to_plot), ncols=len(column_args), figsize=(16,20), dpi=150 )\n",
    "for k, reg in enumerate(regularisations_to_plot):\n",
    "    for j, arg in enumerate(column_args):\n",
    "        no_layers = arg[0]\n",
    "        nodes_per_layer = list( arg[1:] )\n",
    "        training_loss, validation_loss = get_training_validation_loss(no_layers=no_layers, \n",
    "                                                                        nodes_per_layer=nodes_per_layer,\n",
    "                                                                        reg=reg,\n",
    "                                                                        x_valid=x_valid,\n",
    "                                                                        y_valid=y_valid\n",
    "                                                                        )\n",
    "        axs[k, j].plot( validation_loss, label = \"validation\" )\n",
    "        axs[k, j].plot( training_loss, label = \"training\" )\n",
    "        if j == 0:\n",
    "            axs[k, j].set_ylabel(\"$\\lambda$={}\".format(reg))\n",
    "        if k == 0:\n",
    "            axs[k, j].set_title(\"Network size: {}\".format(arg))\n",
    "        \n",
    "axs[k,j].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which network has the lowest validation error?\n",
    "best_network = None\n",
    "best_networksize = None\n",
    "lowest_error = float('inf')\n",
    "lowest_reg = None\n",
    "for (network_size, reg), network_data in trained_networks.items():\n",
    "    nodes_per_layer = list( network_size[1:] )\n",
    "    network_weights = np.asarray(network_data[0], dtype=np.float128)\n",
    "    network_weights = reshape_weights( network_weights, nodes_per_layer )\n",
    "    network_err = cost_network( network_weights, x_valid, y_valid )\n",
    "    if network_err < lowest_error:\n",
    "        lowest_error = network_err\n",
    "        best_network = network_weights\n",
    "        best_networksize = network_size\n",
    "        lowest_reg = reg\n",
    "print(\"Best network size: {}\".format( best_networksize ) )\n",
    "print(\"Best network error on validation set: {}\".format( lowest_error ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "from generate_ising import generate_ising_array\n",
    "from scipy.optimize import minimize\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "from qiskit.opflow.primitive_ops import PauliOp\n",
    "from qiskit.quantum_info import Statevector, Pauli\n",
    "\n",
    "\n",
    "def qaoa_circuit(ising_hamiltonian, p=1):\n",
    "    N = ising_hamiltonian.shape[0]\n",
    "    gammas = ParameterVector(\"γ\", length=p)\n",
    "    betas = ParameterVector(\"β\", length=p)\n",
    "    qaoa_circ = QuantumCircuit(N)\n",
    "    qaoa_circ.h(range(N))\n",
    "    for k in range(p):\n",
    "        add_isingqaoa_layer(qaoa_circ, ising_hamiltonian, gammas[k], betas[k])\n",
    "    return qaoa_circ, betas, gammas\n",
    "\n",
    "def add_isingqaoa_layer(qc, ising_hamiltonian, gamma, beta):\n",
    "    N = ising_hamiltonian.shape[0]\n",
    "    for i in range(N):\n",
    "        qc.rz(2*gamma*ising_hamiltonian[i,i], i)\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            qc.cx(i,j)\n",
    "            qc.rz(2*gamma*ising_hamiltonian[i,j], j)\n",
    "            qc.cx(i,j)\n",
    "    qc.rx(2*beta, range(N))\n",
    "\n",
    "def qiskit_isingop_from_J(J, N):\n",
    "    ops = []\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            op = [\"I\"]*N\n",
    "            op[i] = \"Z\"\n",
    "            op[j] = \"Z\"\n",
    "            pauli_str = \"\".join(op)\n",
    "            if np.abs(J[i,j]) > 1e-6:\n",
    "                pauli = PauliOp(Pauli( pauli_str[::-1] ), coeff=J[i,j] )\n",
    "                ops += [pauli]\n",
    "    op = sum(ops)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_edge = 0.5 #Use prob_edge 0.5, different from training and validation using either 0.3 or 0.7\n",
    "N = 9\n",
    "p = 3\n",
    "\n",
    "def get_rq(J, params, p=3):\n",
    "    qaoa_qc, _, _ = qaoa_circuit(ising_hamiltonian = J, p=p)\n",
    "    ising_op = qiskit_isingop_from_J(J, N)\n",
    "    ising_matrixop = ising_op.to_matrix(massive=False).diagonal().real\n",
    "    min_E, max_E = ising_matrixop.min(), ising_matrixop.max()\n",
    "    def qaoa_expectation( params ):\n",
    "        sv = Statevector( qaoa_qc.assign_parameters(params) ).data\n",
    "        return np.dot( np.conj(sv), ising_matrixop * sv).real\n",
    "    exp = qaoa_expectation(params)\n",
    "    return (max_E - exp) / (max_E - min_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmins = np.loadtxt(\"datasets/xmins.csv\", delimiter=\",\")\n",
    "xminmaxrange = np.loadtxt(\"datasets/xminmaxrange.csv\", delimiter=\",\")\n",
    "ymins = np.loadtxt(\"datasets/ymins.csv\", delimiter=\",\")\n",
    "yminmaxrange = np.loadtxt(\"datasets/yminmaxrange.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_angles( J_s ):\n",
    "    x_inputs = np.zeros( (36, len(J_s)) )\n",
    "    for s in range(len(J_s)):\n",
    "        J = J_s[s]\n",
    "        x = J[ np.triu_indices(N, k=1) ]\n",
    "        x_inputs[:, s] = x\n",
    "    #Normalise x:\n",
    "    xmins_stacked = np.broadcast_to(xmins, (len(J_s),)+xmins.shape).T\n",
    "    xminmaxrange_stacked = np.broadcast_to(xminmaxrange, (len(J_s),)+xminmaxrange.shape).T\n",
    "    ymins_stacked = np.broadcast_to(ymins, (len(J_s),)+ymins.shape).T\n",
    "    yminmaxrange_stacked = np.broadcast_to(yminmaxrange, (len(J_s),)+yminmaxrange.shape).T\n",
    "    x_inputs -= xmins_stacked\n",
    "    x_inputs /= xminmaxrange_stacked\n",
    "    \n",
    "    #Forward pass to network and denormalise y\n",
    "    y = forward_pass(best_network, x=x_inputs)\n",
    "    y *= yminmaxrange_stacked\n",
    "    y += ymins_stacked\n",
    "\n",
    "    #Turn gammas back into negative values:\n",
    "    y[3:, :] *= -1\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_s = [ None for _ in range(8) ] #6 ising instances\n",
    "J_s[0], _ = generate_ising_array(N, prob_edge=0.3, weighted=True, seed=65414)\n",
    "J_s[1], _ = generate_ising_array(N, prob_edge=0.5, weighted=True, seed=11584)\n",
    "J_s[2], _ = generate_ising_array(N, prob_edge=0.7, weighted=True, seed=19721)\n",
    "J_s[3], _ = generate_ising_array(N, prob_edge=0.3, weighted=False, seed=566)\n",
    "J_s[4], _ = generate_ising_array(N, prob_edge=0.5, weighted=False, seed=623)\n",
    "J_s[5], _ = generate_ising_array(N, prob_edge=0.7, weighted=False, seed=66889)\n",
    "J_s[6], _ = generate_ising_array(N, prob_edge=0.9, weighted=True, seed=414)\n",
    "J_s[7], _ = generate_ising_array(N, prob_edge=0.1, weighted=True, seed=641)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = predict_angles(J_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted angles for these ising instances:\")\n",
    "for s in range(8):\n",
    "    print(\"{}: \".format(s), angles[:, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R_q for these ising instances using predicted angles:\")\n",
    "for s in range(8):\n",
    "    r_q = get_rq(J_s[s], params=angles[:, s])\n",
    "    print(\"{}: \".format(s), r_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qaoakit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36f01796ffccae4a93b23469a79663df40024f722d24d8dd28c9c4e2137544c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
